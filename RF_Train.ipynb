{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 训练生成关于Buffer的模型"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A0, A1, A2 as train data, A3 as test data, label = Status, accuracy = 0.9354003309114453\n",
      "A0, A1, A2 as train data, A3 as test data, label = BufferWarning, accuracy = 0.8734623408387886\n",
      "A1, A2, A3 as train data, A0 as test data, label = Status, accuracy = 0.9062808877706892\n",
      "A1, A2, A3 as train data, A0 as test data, label = BufferWarning, accuracy = 0.8144487375325725\n",
      "A2, A3, A0 as train data, A1 as test data, label = Status, accuracy = 0.8832313663574765\n",
      "A2, A3, A0 as train data, A1 as test data, label = BufferWarning, accuracy = 0.8056048944148412\n",
      "A3, A0, A1 as train data, A2 as test data, label = Status, accuracy = 0.9223663338620882\n",
      "A3, A0, A1 as train data, A2 as test data, label = BufferWarning, accuracy = 0.8537837081272744\n",
      "[0.91181973 0.83682492]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "Tree_num=80\n",
    "train_file_nameA0='TrainData/train_A0_buffer.csv'\n",
    "train_file_nameA1='TrainData/train_A1_buffer.csv'\n",
    "train_file_nameA2='TrainData/train_A2_buffer.csv'\n",
    "train_file_nameA3='TrainData/train_A3_buffer.csv'\n",
    "\n",
    "A0=pd.read_csv(train_file_nameA0)\n",
    "A1=pd.read_csv(train_file_nameA1)\n",
    "A2=pd.read_csv(train_file_nameA2)\n",
    "A3=pd.read_csv(train_file_nameA3)\n",
    "Dataset_List = [A0,A1,A2,A3]\n",
    "label_list=[\"Status\", \"BufferWarning\", \"Resolution\"]\n",
    "acc_all = []\n",
    "for i in range(4):\n",
    "    acc_item = []\n",
    "    for j in range(-3,-1):\n",
    "        train_data = Dataset_List[i].append(Dataset_List[(i+1)%4]).append(Dataset_List[(i+2)%4])\n",
    "        test_data = Dataset_List[(i+3)%4]\n",
    "\n",
    "\n",
    "        x_train = pd.concat([train_data.iloc[:,:-10],train_data.iloc[:,125:127]],axis=1)\n",
    "        y_train = train_data.iloc[:,j]\n",
    "\n",
    "        x_test = pd.concat([test_data.iloc[:,:-10],test_data.iloc[:,125:127]],axis=1)\n",
    "        y_test = test_data.iloc[:,j]\n",
    "\n",
    "        rf=RandomForestClassifier(n_estimators=Tree_num, criterion=\"entropy\")\n",
    "        rf.fit(x_train, y_train)\n",
    "        y_pred=rf.predict(x_test)\n",
    "        accuracy=accuracy_score(y_pred,y_test)\n",
    "        print(f'A{i}, A{(i+1)%4}, A{(i+2)%4} as train data, A{(i+3)%4} as test data, label = {label_list[j]}, accuracy = {accuracy}')\n",
    "        joblib.dump(rf, f'Model/RFModel_A{i}A{(i+1)%4}A{(i+2)%4}_{label_list[j]}.pkl', compress=3)\n",
    "        acc_item.append(accuracy)\n",
    "    acc_all.append(acc_item)\n",
    "acc_mat = np.array(acc_all)\n",
    "print(f'{np.average(acc_mat,axis=0)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 训练生成关于resolution的模型"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A0, A1, A2 as train data, A3 as test data, label = Resolution, accuracy = 0.7310560083232183\n",
      "A1, A2, A3 as train data, A0 as test data, label = Resolution, accuracy = 0.6280659429030961\n",
      "A2, A3, A0 as train data, A1 as test data, label = Resolution, accuracy = 0.645881353876016\n",
      "A3, A0, A1 as train data, A2 as test data, label = Resolution, accuracy = 0.6661654135338346\n",
      "[0.91181973 0.83682492 0.66779218]\n"
     ]
    }
   ],
   "source": [
    "Tree_num=80\n",
    "train_file_nameA0='TrainData/train_A0_resolution.csv'\n",
    "train_file_nameA1='TrainData/train_A1_resolution.csv'\n",
    "train_file_nameA2='TrainData/train_A2_resolution.csv'\n",
    "train_file_nameA3='TrainData/train_A3_resolution.csv'\n",
    "\n",
    "A0=pd.read_csv(train_file_nameA0)\n",
    "A1=pd.read_csv(train_file_nameA1)\n",
    "A2=pd.read_csv(train_file_nameA2)\n",
    "A3=pd.read_csv(train_file_nameA3)\n",
    "Dataset_List = [A0,A1,A2,A3]\n",
    "label_list=[\"Status\", \"BufferWarning\", \"Resolution\"]\n",
    "acc_all = []\n",
    "for i in range(4):\n",
    "    acc_item = []\n",
    "    for j in range(-1,0):\n",
    "        train_data = Dataset_List[i].append(Dataset_List[(i+1)%4]).append(Dataset_List[(i+2)%4])\n",
    "        test_data = Dataset_List[(i+3)%4]\n",
    "\n",
    "        x_train = pd.concat([train_data.iloc[:,:-10],train_data.iloc[:,125:127]],axis=1)\n",
    "        y_train = train_data.iloc[:,j]\n",
    "\n",
    "        x_test = pd.concat([test_data.iloc[:,:-10],test_data.iloc[:,125:127]],axis=1)\n",
    "        y_test = test_data.iloc[:,j]\n",
    "        rf=RandomForestClassifier(n_estimators=Tree_num, criterion=\"entropy\")\n",
    "        rf.fit(x_train, y_train)\n",
    "        y_pred=rf.predict(x_test)\n",
    "        accuracy=accuracy_score(y_pred,y_test)\n",
    "        print(f'A{i}, A{(i+1)%4}, A{(i+2)%4} as train data, A{(i+3)%4} as test data, label = {label_list[j]}, accuracy = {accuracy}')\n",
    "        joblib.dump(rf, f'Model/RFModel_A{i}A{(i+1)%4}A{(i+2)%4}_{label_list[j]}.pkl', compress=3)\n",
    "        acc_item.append(accuracy)\n",
    "    acc_all.append(acc_item)\n",
    "acc_mat_all = np.hstack((np.array(acc_mat),np.array(acc_all)))\n",
    "print(f'{np.average(acc_mat_all,axis=0)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------|---------------|---------------|-----------|\n",
      "Type\t\t  |BufferWarning  |BufferStatus   |Resolution |\n",
      "--------------|---------------|---------------|-----------|\n",
      "Paper Accuracy|0.92\t\t\t  |0.842\t\t  |0.669\t  |\n",
      "--------------|---------------|---------------|-----------|\n",
      "My Accuracy   |0.912\t\t  |0.837\t\t  |0.668\t  |\n",
      "--------------|---------------|---------------|-----------|\n",
      "Error         |0.009\t\t  |0.006\t\t  |0.002\t  |\n",
      "--------------|---------------|---------------|-----------|\n"
     ]
    }
   ],
   "source": [
    "paper_accuracy = np.array([0.92,0.842,0.669])\n",
    "my_accuracy = np.average(acc_mat_all,axis=0)\n",
    "error = (paper_accuracy - my_accuracy)/paper_accuracy\n",
    "print('--------------|---------------|---------------|-----------|')\n",
    "print(f'Type\\t\\t  |BufferWarning  |BufferStatus   |Resolution |')\n",
    "print('--------------|---------------|---------------|-----------|')\n",
    "print(f'Paper Accuracy|{round(paper_accuracy[0],3)}\\t\\t\\t  |{round(paper_accuracy[1],3)}\\t\\t  |{round(paper_accuracy[2],3)}\\t  |')\n",
    "print('--------------|---------------|---------------|-----------|')\n",
    "print(f'My Accuracy   |{round(my_accuracy[0],3)}\\t\\t  |{round(my_accuracy[1],3)}\\t\\t  |{round(my_accuracy[2],3)}\\t  |')\n",
    "print('--------------|---------------|---------------|-----------|')\n",
    "print(f'Error         |{round(error[0],3)}\\t\\t  |{round(error[1],3)}\\t\\t  |{round(error[2],3)}\\t  |')\n",
    "print('--------------|---------------|---------------|-----------|')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dip2022",
   "language": "python",
   "name": "dip2022"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
