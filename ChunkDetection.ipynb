{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program\\Anaconda\\envs\\dip2022\\lib\\site-packages\\scapy\\layers\\ipsec.py:471: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  cipher=algorithms.Blowfish,\n",
      "D:\\Program\\Anaconda\\envs\\dip2022\\lib\\site-packages\\scapy\\layers\\ipsec.py:485: CryptographyDeprecationWarning: CAST5 has been deprecated\n",
      "  cipher=algorithms.CAST5,\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scapy.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunk Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from math import *\n",
    "import scapy.layers as layers\n",
    "IP = layers.inet.IP\n",
    "\n",
    "GET_THRESH = 300 # bytes\n",
    "DOWN_THRESH = 300  # bytes\n",
    "VIDEO_CHUNK_GETSIZE = 700 # bytes\n",
    "AUDIO_CHUNK_GETSIZE = 600 # bytes\n",
    "NETINFO_NUM = 25\n",
    "\n",
    "class Chunk():\n",
    "    def __init__(self, start_time = 0, server_ip='',ttfb = 0, download_time = 0, slack_time = 0, get_size=0, chunk_size = 0, type=\"\", protocol=\"\"):\n",
    "        self.start_time = start_time\n",
    "        self.server_ip = server_ip\n",
    "        self.ttfb = ttfb\n",
    "        self.download_time = download_time\n",
    "        self.slack_time = slack_time\n",
    "        self.get_size = get_size\n",
    "        self.chunk_size = chunk_size\n",
    "        self.type = type\n",
    "        self.protocol = protocol\n",
    "    def __str__(self):\n",
    "        return f\"{self.start_time} {self.ttfb} {self.download_time} {self.slack_time} {self.get_size} {self.chunk_size} {self.type} {self.protocol}\"\n",
    "    def __repr__(self):\n",
    "        return f\"{self.start_time} {self.ttfb} {self.download_time} {self.slack_time} {self.get_size} {self.chunk_size} {self.type} {self.protocol}\"\n",
    "\n",
    "\n",
    "def isUplink(p):\n",
    "    # IP = scapy.layers.inet.IP\n",
    "    return p[IP].src.startswith('192.168.')\n",
    "\n",
    "def detectAV(c):\n",
    "    if abs(c.get_size-VIDEO_CHUNK_GETSIZE) > abs(c.get_size-AUDIO_CHUNK_GETSIZE):\n",
    "        flag=0\n",
    "    else:\n",
    "        flag=1\n",
    "    if c.chunk_size<=80*1024:\n",
    "        flag=2\n",
    "    return flag\n",
    "\n",
    "def chunkDetection(filename):\n",
    "    a = rdpcap(filename)\n",
    "    meta_time = float(a[0].time)\n",
    "    chunk = {}\n",
    "    chunks = []\n",
    "    downFlag = {}\n",
    "    # IP = scapy.layers.inet.IP\n",
    "    for p in a:\n",
    "        if p.haslayer(IP):\n",
    "            ipSrc=p[IP].src\n",
    "            ipDst=p[IP].dst\n",
    "            pLen=p[IP].len\n",
    "            pHdr=p[IP].ihl*4\n",
    "            ip_time=float(p.time)\n",
    "            if isUplink(p) and pLen-pHdr > GET_THRESH:\n",
    "                if ipDst in chunk:\n",
    "                    chunk[ipDst].slack_time = ip_time - chunk[ipDst].download_time\n",
    "                    avFlag=detectAV(chunk[ipDst])\n",
    "                    if avFlag==0:\n",
    "                        # chunk[ipDst].type='a'\n",
    "                        chunks.append(chunk[ipDst])\n",
    "                    elif avFlag==1:\n",
    "                        # chunk[ipDst].type='v'\n",
    "                        chunks.append(chunk[ipDst])\n",
    "                    else:\n",
    "                        chunk.pop(ipDst)\n",
    "                        downFlag.pop(ipDst)\n",
    "                chunk[ipDst] = Chunk(start_time=ip_time, get_size=pLen-pHdr, server_ip=ipDst)\n",
    "                downFlag[ipDst] = False\n",
    "            elif not isUplink(p) and pLen > DOWN_THRESH:\n",
    "                if ipSrc in chunk:\n",
    "                    if not downFlag[ipSrc]:\n",
    "                        chunk[ipSrc].ttfb = ip_time\n",
    "                        downFlag[ipSrc] = True\n",
    "                    chunk[ipSrc].download_time = ip_time\n",
    "                    chunk[ipSrc].chunk_size += pLen - pHdr\n",
    "                    chunk[ipSrc].protocol = p.proto\n",
    "    \n",
    "    for c in chunk.values():\n",
    "        avFlag=detectAV(c)\n",
    "        if avFlag==0:\n",
    "            # c.type='a'\n",
    "            chunks.append(c)\n",
    "        elif avFlag==1:\n",
    "            # c.type='v'\n",
    "            chunks.append(c)\n",
    "    return meta_time, chunks\n",
    "\n",
    "filename = 'RequetDataSetNew/A0/PCAP_FILES/baseline_Jan17_exp_31.pcap'\n",
    "meta_time, chunks=chunkDetection(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chunk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [9], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(chunk)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'chunk' is not defined"
     ]
    }
   ],
   "source": [
    "print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Time:17.363425970077515\n",
      "lenth:84540\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "filename = 'RequetDataSetNew/A0/PCAP_FILES/baseline_Jan17_exp_31.pcap'\n",
    "pacpfile = rdpcap(filename)\n",
    "end = time.time()\n",
    "print(f\"Use Time:{end - start}\")\n",
    "print(f'lenth:{len(pacpfile)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253\n",
      "145\n",
      "90\n",
      "379\n",
      "52\n",
      "510\n",
      "90\n",
      "52\n",
      "52\n",
      "1470\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(pacpfile[i][IP].len)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shabi\n",
      "6\n",
      "shabi\n",
      "6\n",
      "shabi\n",
      "6\n",
      "shabi\n",
      "6\n",
      "84496\n"
     ]
    }
   ],
   "source": [
    "GET_THRESH = 300  # bytes\n",
    "DOWN_THRESH = 300  # bytes\n",
    "VIDEO_CHUNK_GETSIZE = 700  # bytes\n",
    "AUDIO_CHUNK_GETSIZE = 600  # bytes\n",
    "import scapy.layers as layers\n",
    "\n",
    "def isUplink(p):\n",
    "    return p[IP].src.startswith('192.168.')\n",
    "def detectAV(c):\n",
    "    if abs(c.get_size-VIDEO_CHUNK_GETSIZE) > abs(c.get_size-AUDIO_CHUNK_GETSIZE):\n",
    "        flag=0\n",
    "    else:\n",
    "        flag=1\n",
    "    if c.chunk_size<=80*1024:\n",
    "        flag=2\n",
    "    return flag\n",
    "chunk = {}\n",
    "chunks = []\n",
    "downFlag = {}\n",
    "#  用show显示包的内容\n",
    "count=0\n",
    "# print(pacpfile[0].show())\n",
    "IP = layers.inet.IP\n",
    "i = 0\n",
    "for p in pacpfile:\n",
    "    if p.haslayer(IP):\n",
    "        ipSrc = p[IP].src\n",
    "        ipDst = p[IP].dst\n",
    "        pLen = p[IP].len\n",
    "        pHdr = p[IP].ihl*4\n",
    "        i+=1\n",
    "        if int(p[IP].ihl) != 5:\n",
    "            print(\"shabi\")\n",
    "            print(p[IP].ihl)\n",
    "        ip_time = float(p.time)\n",
    "        end_time = ip_time\n",
    "        # print(p.show())\n",
    "        if isUplink(p) and pLen-pHdr > GET_THRESH:\n",
    "            # print(f'ipSrc:{ipSrc}, ipDst:{ipDst}, pLen:{pLen}, pHdr:{pHdr}, ip_time:{ip_time}, end_time:{end_time}')\n",
    "            if ipDst in chunk:\n",
    "                chunk[ipDst].slack_time = ip_time - chunk[ipDst].download_time\n",
    "                avFlag = detectAV(chunk[ipDst])\n",
    "                if avFlag == 0:\n",
    "                    # chunk[ipDst].type='a'\n",
    "                    chunks.append(chunk[ipDst])\n",
    "                elif avFlag == 1:\n",
    "                    # chunk[ipDst].type='v'\n",
    "                    chunks.append(chunk[ipDst])\n",
    "                else:\n",
    "                    chunk.pop(ipDst)\n",
    "                    downFlag.pop(ipDst)\n",
    "            chunk[ipDst] = Chunk(start_time=ip_time, get_size=pLen-pHdr, server_ip=ipDst)\n",
    "            downFlag[ipDst] = False\n",
    "        elif not isUplink(p) and pLen > DOWN_THRESH:\n",
    "            if ipSrc in chunk:\n",
    "                if not downFlag[ipSrc]:\n",
    "                    chunk[ipSrc].ttfb = ip_time\n",
    "                    downFlag[ipSrc] = True\n",
    "                chunk[ipSrc].download_time = ip_time\n",
    "                chunk[ipSrc].chunk_size += pLen - pHdr\n",
    "                chunk[ipSrc].protocol = p.proto\n",
    "for c in chunk.values():\n",
    "    avFlag=detectAV(c)\n",
    "    if avFlag==0:\n",
    "        # c.type='a'\n",
    "        chunks.append(c)\n",
    "    elif avFlag==1:\n",
    "        # c.type='v'\n",
    "        chunks.append(c)\n",
    "# f\"{self.start_time} {self.ttfb} {self.download_time} {self.slack_time} {self.get_size} {self.chunk_size} {self.type} {self.protocol}\"\n",
    "print(i)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "6"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p[IP].proto"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['start_time', 'server_ip', 'type', 'ttfb', 'download_time', 'get_size', 'chunk_size', 'rel_start_time', 'rel_end_time']\n",
    "df_chunk=pd.DataFrame(columns=columns)\n",
    "\n",
    "\n",
    "for c in chunks:\n",
    "    start_time = c.start_time\n",
    "    server_ip = c.server_ip\n",
    "    type = c.type\n",
    "    ttfb = c.ttfb - c.start_time\n",
    "    download_time = c.download_time - c.start_time\n",
    "    get_size = c.get_size\n",
    "    chunk_size = c.chunk_size\n",
    "    rel_start_time = start_time-meta_time\n",
    "    rel_end_time = c.download_time - meta_time\n",
    "    s = pd.Series([start_time, server_ip, type, ttfb, download_time, get_size, chunk_size, rel_start_time, rel_end_time], index=columns)\n",
    "    df_chunk.loc[len(df_chunk)] = s\n",
    "\n",
    "av_getsize_gap = df_chunk.get_size.mean()\n",
    "\n",
    "for i in range(len(df_chunk)):\n",
    "    df_chunk.loc[i, 'type'] = 'a' if df_chunk.loc[i, 'get_size'] < av_getsize_gap else 'v'\n",
    "\n",
    "df_chunk.sort_values(by='start_time', inplace=True)\n",
    "df_chunk.to_csv('results/chunk_detection/A0/baseline_Jan17_exp_30.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['start_time', 'server_ip', 'type', 'ttfb', 'download_time', 'get_size', 'chunk_size', 'rel_start_time', 'rel_end_time']\n",
    "df_chunk=pd.DataFrame(columns=columns)\n",
    "df_chunk\n",
    "s = pd.Series([start_time, server_ip, type, ttfb, download_time, get_size, chunk_size, rel_start_time, rel_end_time], index=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "(56, 9)"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_chunk.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = df_chunk['start_time'].min()\n",
    "end_time = df_chunk['start_time'].max()\n",
    "\n",
    "columns=['timestamp']+[str(i) for i in range(1,121)]\n",
    "\n",
    "df_120features=pd.DataFrame(columns=columns)\n",
    "\n",
    "for t_msec in range(int(start_time*1000), int(end_time*1000+100), 100):\n",
    "    s = [t_msec]\n",
    "    t = t_msec/1000\n",
    "    for w in range(1, 21):\n",
    "        period = w*10.0\n",
    "        if t-period<start_time:\n",
    "            total_number_of_chunks_v = -1\n",
    "            avg_chunk_size_v = -1\n",
    "            download_time_v = -1\n",
    "            total_number_of_chunks_a = -1\n",
    "            avg_chunk_size_a = -1\n",
    "            download_time_a = -1\n",
    "        else:\n",
    "            total_number_of_chunks_v = df_chunk[(df_chunk['type']=='v') & (df_chunk['start_time']>t-period) & (df_chunk['start_time']<t)].shape[0]\n",
    "            avg_chunk_size_v = df_chunk[(df_chunk['type']=='v') & (df_chunk['start_time']>t-period) & (df_chunk['start_time']<t)]['chunk_size'].mean()\n",
    "            download_time_v = df_chunk[(df_chunk['type']=='v') & (df_chunk['start_time']>t-period) & (df_chunk['start_time']<t)]['download_time'].sum()\n",
    "            total_number_of_chunks_a = df_chunk[(df_chunk['type']=='a') & (df_chunk['start_time']>t-period) & (df_chunk['start_time']<t)].shape[0]\n",
    "            avg_chunk_size_a = df_chunk[(df_chunk['type']=='a') & (df_chunk['start_time']>t-period) & (df_chunk['start_time']<t)]['chunk_size'].mean()\n",
    "            download_time_a = df_chunk[(df_chunk['type']=='a') & (df_chunk['start_time']>t-period) & (df_chunk['start_time']<t)]['download_time'].sum()\n",
    "        s += [total_number_of_chunks_v, avg_chunk_size_v, download_time_v, total_number_of_chunks_a, avg_chunk_size_a, download_time_a]\n",
    "    \n",
    "    df_120features.loc[len(df_120features)] = s\n",
    "\n",
    "df_120features.to_csv('results/120features/A0/baseline_Jan17_exp_30.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32mD:\\Program\\Anaconda\\envs\\dip2022\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3803\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3802\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3803\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3804\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32mD:\\Program\\Anaconda\\envs\\dip2022\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mD:\\Program\\Anaconda\\envs\\dip2022\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2263\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2273\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [12], line 15\u001B[0m\n\u001B[0;32m     12\u001B[0m video_chunk_prev \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mchunk_size\u001B[39m\u001B[38;5;124m'\u001B[39m:[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdownload_time\u001B[39m\u001B[38;5;124m'\u001B[39m:[\u001B[38;5;241m0\u001B[39m]}\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(df_audio_chunk)):\n\u001B[1;32m---> 15\u001B[0m     audio_chunk_prev[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mchunk_size\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mappend(audio_chunk_prev[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mchunk_size\u001B[39m\u001B[38;5;124m'\u001B[39m][i] \u001B[38;5;241m+\u001B[39m df_audio_chunk\u001B[38;5;241m.\u001B[39mloc[i, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mchunk_size\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m     16\u001B[0m     audio_chunk_prev[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdownload_time\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mappend(audio_chunk_prev[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdownload_time\u001B[39m\u001B[38;5;124m'\u001B[39m][i] \u001B[38;5;241m+\u001B[39m df_audio_chunk\u001B[38;5;241m.\u001B[39mloc[i, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdownload_time\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(df_video_chunk)):\n",
      "File \u001B[1;32mD:\\Program\\Anaconda\\envs\\dip2022\\lib\\site-packages\\pandas\\core\\indexing.py:1066\u001B[0m, in \u001B[0;36m_LocationIndexer.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   1064\u001B[0m     key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(com\u001B[38;5;241m.\u001B[39mapply_if_callable(x, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m key)\n\u001B[0;32m   1065\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_is_scalar_access(key):\n\u001B[1;32m-> 1066\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_value\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtakeable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_takeable\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1067\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_tuple(key)\n\u001B[0;32m   1068\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1069\u001B[0m     \u001B[38;5;66;03m# we by definition only have the 0th axis\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Program\\Anaconda\\envs\\dip2022\\lib\\site-packages\\pandas\\core\\frame.py:3921\u001B[0m, in \u001B[0;36mDataFrame._get_value\u001B[1;34m(self, index, col, takeable)\u001B[0m\n\u001B[0;32m   3915\u001B[0m engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex\u001B[38;5;241m.\u001B[39m_engine\n\u001B[0;32m   3917\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex, MultiIndex):\n\u001B[0;32m   3918\u001B[0m     \u001B[38;5;66;03m# CategoricalIndex: Trying to use the engine fastpath may give incorrect\u001B[39;00m\n\u001B[0;32m   3919\u001B[0m     \u001B[38;5;66;03m#  results if our categories are integers that dont match our codes\u001B[39;00m\n\u001B[0;32m   3920\u001B[0m     \u001B[38;5;66;03m# IntervalIndex: IntervalTree has no get_loc\u001B[39;00m\n\u001B[1;32m-> 3921\u001B[0m     row \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3922\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m series\u001B[38;5;241m.\u001B[39m_values[row]\n\u001B[0;32m   3924\u001B[0m \u001B[38;5;66;03m# For MultiIndex going through engine effectively restricts us to\u001B[39;00m\n\u001B[0;32m   3925\u001B[0m \u001B[38;5;66;03m#  same-length tuples; see test_get_set_value_no_partial_indexing\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Program\\Anaconda\\envs\\dip2022\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3803\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[0;32m   3804\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m-> 3805\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3806\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3807\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3808\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3809\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m   3810\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: 0"
     ]
    }
   ],
   "source": [
    "start_time = df_chunk['start_time'].min()\n",
    "end_time = df_chunk['start_time'].max()\n",
    "\n",
    "columns=['timestamp']+[str(i) for i in range(1,121)]\n",
    "\n",
    "df_120features=pd.DataFrame(columns=columns)\n",
    "\n",
    "df_audio_chunk=df_chunk[df_chunk.type=='a']\n",
    "df_video_chunk=df_chunk[df_chunk.type=='v']\n",
    "\n",
    "audio_chunk_prev = {'chunk_size':[0], 'download_time':[0]}\n",
    "video_chunk_prev = {'chunk_size':[0], 'download_time':[0]}\n",
    "\n",
    "for i in range(len(df_audio_chunk)):\n",
    "    audio_chunk_prev['chunk_size'].append(audio_chunk_prev['chunk_size'][i] + df_audio_chunk.loc[i, 'chunk_size'])\n",
    "    audio_chunk_prev['download_time'].append(audio_chunk_prev['download_time'][i] + df_audio_chunk.loc[i, 'download_time'])\n",
    "\n",
    "for i in range(len(df_video_chunk)):\n",
    "    video_chunk_prev['chunk_size'].append(video_chunk_prev['chunk_size'][i] + df_video_chunk.loc[i, 'chunk_size'])\n",
    "    video_chunk_prev['download_time'].append(video_chunk_prev['download_time'][i] + df_video_chunk.loc[i, 'download_time'])\n",
    "\n",
    "\n",
    "for t_msec in range(int(start_time*1000), int(end_time*1000+100), 100):\n",
    "    s = [t_msec]\n",
    "    t = t_msec/1000\n",
    "    for w in range(1, 21):\n",
    "        l_audio = 0\n",
    "        r_audio = 0\n",
    "        l_video = 0\n",
    "        r_video = 0\n",
    "        period = w * 10.0\n",
    "        l_t = t - period\n",
    "        if l_t<start_time:\n",
    "            total_number_of_chunks_v = -1\n",
    "            avg_chunk_size_v = -1\n",
    "            download_time_v = -1\n",
    "            total_number_of_chunks_a = -1\n",
    "            avg_chunk_size_a = -1\n",
    "            download_time_a = -1\n",
    "        else:\n",
    "            while df_audio_chunk.loc[l_audio, 'start_time'] < l_t:\n",
    "                l_audio += 1\n",
    "            while df_audio_chunk.loc[r_audio, 'start_time'] <= t:\n",
    "                r_audio += 1\n",
    "            while df_video_chunk.loc[l_video, 'start_time'] < l_t:\n",
    "                l_video += 1\n",
    "            while df_video_chunk.loc[r_video, 'start_time'] <= t:\n",
    "                r_video += 1\n",
    "            total_number_of_chunks_v = r_video - l_video \n",
    "            avg_chunk_size_v = video_chunk_prev['chunk_size'][r_video] - video_chunk_prev['chunk_size'][l_video]\n",
    "            download_time_v = video_chunk_prev['download_time'][r_video] - video_chunk_prev['download_time'][l_video]\n",
    "            total_number_of_chunks_a = r_audio - l_audio\n",
    "            avg_chunk_size_a = audio_chunk_prev['chunk_size'][r_audio] - audio_chunk_prev['chunk_size'][l_audio]\n",
    "            download_time_a = audio_chunk_prev['download_time'][r_audio-1] - audio_chunk_prev['download_time'][l_audio-1]\n",
    "        s += [total_number_of_chunks_v, avg_chunk_size_v, download_time_v, total_number_of_chunks_a, avg_chunk_size_a, download_time_a]\n",
    "    \n",
    "    df_120features.loc[len(df_120features)] = s\n",
    "\n",
    "df_120features.to_csv('results/120features/A0/baseline_Jan17_exp_30.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def inet_to_str(inet):\n",
    "    try:\n",
    "        return socket.inet_ntop(socket.AF_INET,inet)\n",
    "    except:\n",
    "        return False\n",
    "def isUplink(ip):\n",
    "    return inet_to_str(ip.src)[:8] == '192.168.' and (ip.len + 14) > GET_THRESH\n",
    "def isDownLink(ip):\n",
    "    return inet_to_str(ip.src)[:8] != '192.168.' and (ip.len + 14) > GET_THRESH"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241\n"
     ]
    }
   ],
   "source": [
    "import dpkt\n",
    "\n",
    "filename = 'RequetDataSetNew/A0/PCAP_FILES/baseline_Jan17_exp_31.pcap'\n",
    "f = open(filename,'rb')\n",
    "pcap = dpkt.pcap.Reader(f)\n",
    "\n",
    "\n",
    "times = []\n",
    "ip_srcs = []\n",
    "ip_dsts = []\n",
    "ip_len = []\n",
    "ip_ihls = []\n",
    "ip_protos = []\n",
    "Get_Start_Time = []\n",
    "Last_Down_Time = []\n",
    "Down_Time = 0\n",
    "i = 0\n",
    "count = 0\n",
    "for ts,buf in pcap:\n",
    "    if count==0:\n",
    "        unix_start = ts\n",
    "    # ts是时间戳\n",
    "    times.append(ts)\n",
    "    eth=dpkt.ethernet.Ethernet(buf)\n",
    "    #这里也是对没有IP段的包过滤掉\n",
    "    if eth.type != dpkt.ethernet.ETH_TYPE_IP:\n",
    "        continue\n",
    "    ip = eth.data\n",
    "    ip_src = inet_to_str(ip.src) #\n",
    "    ip_dst = inet_to_str(ip.dst) #\n",
    "    ip_srcs.append(ip_src) #  src\n",
    "    ip_dsts.append(ip_dst) #  dst\n",
    "    ip_len.append(ip.len)  #  len\n",
    "    ip_protos.append(ip.p) #  proto:协议号tcp是6\n",
    "    ip_ihls.append(ip.hl)  #  ihl\n",
    "    Last_ip = ip\n",
    "    if isDownLink(ip):\n",
    "        Down_Time = ts\n",
    "    if isUplink(ip):\n",
    "        i+=1\n",
    "        idx = ip\n",
    "        Get_Start_Time.append(ts)\n",
    "        Last_Down_Time.append(Down_Time)\n",
    "    count +=1\n",
    "unix_end = ts\n",
    "print(i)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading pcap file...\n",
      "Parsing pcap file...\n",
      "Calcilate chunk...\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "from scapy.all import *\n",
    "from math import *\n",
    "import pandas as pd\n",
    "import dpkt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "GET_THRESH = 300  # bytes\n",
    "DOWN_THRESH = 300  # bytes\n",
    "VIDEO_CHUNK_GETSIZE = 700  # bytes\n",
    "AUDIO_CHUNK_GETSIZE = 600  # bytes\n",
    "\n",
    "class Chunk():\n",
    "    def __init__(self, GetTimestamp=0, GetSize=0, DownStart=0, DownEnd=0, DownSize=0, type=0, GetProtocol=\"\", serverIP = \"\"):\n",
    "        self.GetTimestamp = GetTimestamp  #发送请求的时间戳\n",
    "        self.GetSize = GetSize  #Get请求的长度\n",
    "        self.DownStart = DownStart  #块的第一个下行包的时间戳\n",
    "        self.DownEnd = DownEnd  #块的最后一个下行包的时间戳\n",
    "        self.DownSize = DownSize  #块的所有下行包的大小之和\n",
    "        self.type = type  #类型：视频或音频\n",
    "        self.GetProtocol = GetProtocol  #协议\n",
    "        self.serverIP = serverIP\n",
    "    def getGetTimestamp(self):\n",
    "        return self.GetTimestamp\n",
    "\n",
    "    def getDownEnd(self):\n",
    "        return  self.DownEnd\n",
    "\n",
    "    def getServerIP(self):\n",
    "        return self.serverIP\n",
    "\n",
    "    def getGetSize(self):\n",
    "        return self.GetSize\n",
    "\n",
    "    def setType(self, newType):\n",
    "        self.type = newType\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        self_small = True\n",
    "        A = self.GetTimestamp\n",
    "        B = other.GetTimestamp\n",
    "        self_small = A < B\n",
    "        return self_small\n",
    "\n",
    "    def detectAV(self):\n",
    "        # 论文里是根据GetSize, DownSize, GetProtocol来区分视频块，音频块和后台流量的\n",
    "        flag = 0\n",
    "        if self.DownSize <= 80*1024:\n",
    "            flag = 2\n",
    "        else:\n",
    "            if abs(self.GetSize-VIDEO_CHUNK_GETSIZE) > abs(self.GetSize-AUDIO_CHUNK_GETSIZE): #判断这个大小更接近视频块还是音频块\n",
    "                flag = 0\n",
    "            else:\n",
    "                flag = 1\n",
    "        # 基于协议号的筛选\n",
    "        return flag\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self.serverIP} {self.GetTimestamp} {self.GetSize} {self.DownStart} {self.DownEnd} {self.DownSize} {self.type} {self.GetProtocol}\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.serverIP} {self.GetTimestamp} {self.GetSize} {self.DownStart} {self.DownEnd} {self.DownSize} {self.type} {self.GetProtocol}\"\n",
    "\n",
    "def inet_to_str(inet):\n",
    "    try:\n",
    "        return socket.inet_ntop(socket.AF_INET, inet)\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def isUplink(src):\n",
    "    return src[0:7] == '192.168'\n",
    "\n",
    "def ChunkDetection(filename):\n",
    "    #解析pcap文件\n",
    "    print(\"Reading pcap file...\")\n",
    "\n",
    "    #读入pcap文件\n",
    "    f = open(filename, 'rb')\n",
    "    pcap = dpkt.pcap.Reader(f)\n",
    "\n",
    "    # meta_time = 0\n",
    "    i = 0\n",
    "    #pcap是Reader类，无法切片，目前先这样写\n",
    "    # for ts, buf in pcap:\n",
    "    #     i += 1\n",
    "    #     if i == 1:\n",
    "    #         meta_time = ts\n",
    "    #         break\n",
    "    # end_time = meta_time\n",
    "    chunks = {}\n",
    "    chunksValue = []\n",
    "    downFlag = {}  #用于标识是不是第一个下行报文\n",
    "\n",
    "    print(\"Parsing pcap file...\")\n",
    "\n",
    "    times = []\n",
    "    ip_srcs = []\n",
    "    ip_dsts = []\n",
    "    ip_lens = []\n",
    "    ip_ihls = []\n",
    "    ip_protos = []\n",
    "    for ts, buf in pcap:\n",
    "        # 这里也是对没有IP段的包过滤掉\n",
    "        eth = dpkt.ethernet.Ethernet(buf)\n",
    "        if eth.type != dpkt.ethernet.ETH_TYPE_IP:\n",
    "            continue\n",
    "        # ts是时间戳\n",
    "        times.append(ts)\n",
    "        ip = eth.data\n",
    "        ip_src = inet_to_str(ip.src)  #\n",
    "        ip_dst = inet_to_str(ip.dst)  #\n",
    "        ip_srcs.append(ip_src)  # src\n",
    "        ip_dsts.append(ip_dst)  # dst\n",
    "        ip_lens.append(ip.len)  # len\n",
    "        ip_protos.append(ip.p)  # proto:协议号tcp是6\n",
    "        ip_ihls.append(ip.hl)  # ihl\n",
    "\n",
    "    print(\"Calcilate chunk...\")\n",
    "    sumGetSize = 0\n",
    "    for n in range(len(ip_srcs)):\n",
    "        ipSrc = ip_srcs[n]\n",
    "        ipDst = ip_dsts[n]\n",
    "        ipSize = ip_lens[n] - ip_ihls[n] * 4\n",
    "        ipTime = times[n]\n",
    "        ipProto = ip_protos[n]\n",
    "        #end_time = ipTime\n",
    "        if isUplink(ipSrc) and ipSize > GET_THRESH:\n",
    "            # 上行包，2种情况：（1）已经出现过的，则处理上一个发往这个站点的块，并初始化新块；（2）没有出现过，初始化新块\n",
    "            if ipDst in chunks:  #意味着以这一ip地址为目的地址的块已经结束，以这一ip地址为目的地址的块马上开始\n",
    "                #筛选：刚刚结束的块是否是音频或视频块\n",
    "                avFlag = chunks[ipDst].detectAV()\n",
    "                if not avFlag == 2:  # 音频块\n",
    "                    sumGetSize += chunks[ipDst].getGetSize()\n",
    "                    chunksValue.append(chunks[ipDst])\n",
    "                else:  # 后台流量\n",
    "                    chunks.pop(ipDst)  # 抛弃这个块\n",
    "                    downFlag.pop(ipDst)\n",
    "            #初始化新块\n",
    "            chunks[ipDst] = Chunk(GetTimestamp=ipTime, GetSize=ipSize, GetProtocol=ipProto, serverIP = ipDst)\n",
    "            downFlag[ipDst] = False\n",
    "        elif not isUplink(ipSrc) and ipSize > DOWN_THRESH:\n",
    "            if ipSrc in chunks:\n",
    "            # 下行包，2种情况：（1）是Get请求的第一个下行包，记录时间，更新大小和时间；（2）不是Get请求的第一个下行包，更新大小和时间\n",
    "                if not downFlag[ipSrc]:\n",
    "                    chunks[ipSrc].DownStart = ipTime  # 收到第一个下行包的时间\n",
    "                    downFlag[ipSrc] = True\n",
    "                chunks[ipSrc].DownEnd = ipTime\n",
    "                chunks[ipSrc].DownSize += ipSize\n",
    "                chunks[ipSrc].protocol = ipProto\n",
    "\n",
    "    for c in chunks.values():\n",
    "        avFlag = c.detectAV()\n",
    "        if not avFlag == 2:  # 音频块\n",
    "            sumGetSize += c.getGetSize()\n",
    "            chunksValue.append(c)\n",
    "\n",
    "    # 区分音频块和视频块\n",
    "    chunkNum = len(chunksValue)\n",
    "    ave_GetSize = sumGetSize / chunkNum\n",
    "    for s_chunk in chunksValue:\n",
    "        if (s_chunk.getGetSize() > ave_GetSize):\n",
    "            s_chunk.setType(0)\n",
    "        else:\n",
    "            s_chunk.setType(1)\n",
    "\n",
    "    return chunkNum, chunksValue\n",
    "\n",
    "def getChunkMetrics(chunkNum, chunksValue):\n",
    "    sortChunks = sorted(chunksValue)\n",
    "    #顺序：'start_time', 'type', 'ttfb', 'download_time', 'end_time', 'get_size', 'chunk_size'\n",
    "    output_data = np.zeros((chunkNum, 7))\n",
    "    i = 0\n",
    "    for c in chunksValue:\n",
    "        start_time = c.GetTimestamp\n",
    "        ttfb = c.DownStart - start_time\n",
    "        download_time = c.DownEnd - c.DownStart\n",
    "        end_time = c.DownEnd\n",
    "        get_size = c.GetSize\n",
    "        chunk_size = c.DownSize\n",
    "        type = c.type\n",
    "        output_data[i] = np.array([start_time, type, ttfb, download_time, end_time, get_size, chunk_size])\n",
    "        i += 1\n",
    "    print(i)\n",
    "    return output_data\n",
    "\n",
    "filename = 'RequetDataSetNew/A0/PCAP_FILES/baseline_Jan17_exp_31.pcap'\n",
    "# 1. chunkDetection\n",
    "chunkNum, chunksValue0 = ChunkDetection(filename)\n",
    "# 2. chunkMetrics\n",
    "output = getChunkMetrics(chunkNum, chunksValue0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.5162096103863070e+09,\n        0.0000000000000000e+00,\n        2.4419069290161133e-02, ...,\n        1.5162096129504409e+09,\n        1.2470000000000000e+03,\n        6.2404900000000000e+05],\n       [1.5162096110822229e+09,\n        1.0000000000000000e+00,\n        5.6140422821044922e-03, ...,\n        1.5162096145293260e+09,\n        3.1000000000000000e+02,\n        2.1291900000000000e+06],\n       [1.5162096146351621e+09,\n        1.0000000000000000e+00,\n        3.3547878265380859e-03, ...,\n        1.5162096151560409e+09,\n        3.1600000000000000e+02,\n        1.5870910000000000e+06],\n       ...,\n       [1.5162100717320600e+09,\n        0.0000000000000000e+00,\n        1.6271114349365234e-02, ...,\n        1.5162100719303150e+09,\n        1.2600000000000000e+03,\n        1.9892400000000000e+05],\n       [1.5162096243067961e+09,\n        1.0000000000000000e+00,\n        5.7280063629150391e-03, ...,\n        1.5162096256747489e+09,\n        3.1900000000000000e+02,\n        8.9297000000000000e+05],\n       [1.5162100739820700e+09,\n        0.0000000000000000e+00,\n        1.5187025070190430e-02, ...,\n        1.5162100755290790e+09,\n        1.3730000000000000e+03,\n        1.9819550000000000e+06]])"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "dip2022",
   "language": "python",
   "display_name": "dip2022"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
