{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: No libpcap provider available ! pcap won't be used\n",
      "D:\\Program\\Anaconda\\envs\\dip2022\\lib\\site-packages\\scapy\\layers\\ipsec.py:471: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  cipher=algorithms.Blowfish,\n",
      "D:\\Program\\Anaconda\\envs\\dip2022\\lib\\site-packages\\scapy\\layers\\ipsec.py:485: CryptographyDeprecationWarning: CAST5 has been deprecated\n",
      "  cipher=algorithms.CAST5,\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scapy.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunk Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from math import *\n",
    "import scapy.layers as layers\n",
    "IP = layers.inet.IP\n",
    "\n",
    "GET_THRESH = 300 # bytes\n",
    "DOWN_THRESH = 300  # bytes\n",
    "VIDEO_CHUNK_GETSIZE = 700 # bytes\n",
    "AUDIO_CHUNK_GETSIZE = 600 # bytes\n",
    "NETINFO_NUM = 25\n",
    "\n",
    "class Chunk():\n",
    "    def __init__(self, start_time = 0, server_ip='',ttfb = 0, download_time = 0, slack_time = 0, get_size=0, chunk_size = 0, type=\"\", protocol=\"\"):\n",
    "        self.start_time = start_time\n",
    "        self.server_ip = server_ip\n",
    "        self.ttfb = ttfb\n",
    "        self.download_time = download_time\n",
    "        self.slack_time = slack_time\n",
    "        self.get_size = get_size\n",
    "        self.chunk_size = chunk_size\n",
    "        self.type = type\n",
    "        self.protocol = protocol\n",
    "    def __str__(self):\n",
    "        return f\"{self.start_time} {self.ttfb} {self.download_time} {self.slack_time} {self.get_size} {self.chunk_size} {self.type} {self.protocol}\"\n",
    "    def __repr__(self):\n",
    "        return f\"{self.start_time} {self.ttfb} {self.download_time} {self.slack_time} {self.get_size} {self.chunk_size} {self.type} {self.protocol}\"\n",
    "\n",
    "\n",
    "def isUplink(p):\n",
    "    # IP = scapy.layers.inet.IP\n",
    "    return p[IP].src.startswith('192.168.')\n",
    "\n",
    "def detectAV(c):\n",
    "    if abs(c.get_size-VIDEO_CHUNK_GETSIZE) > abs(c.get_size-AUDIO_CHUNK_GETSIZE):\n",
    "        flag=0\n",
    "    else:\n",
    "        flag=1\n",
    "    if c.chunk_size<=80*1024:\n",
    "        flag=2\n",
    "    return flag\n",
    "\n",
    "def chunkDetection(filename):\n",
    "    a = rdpcap(filename)\n",
    "    meta_time = float(a[0].time)\n",
    "    chunk = {}\n",
    "    chunks = []\n",
    "    downFlag = {}\n",
    "    # IP = scapy.layers.inet.IP\n",
    "    for p in a:\n",
    "        if p.haslayer(IP):\n",
    "            ipSrc=p[IP].src\n",
    "            ipDst=p[IP].dst\n",
    "            pLen=p[IP].len\n",
    "            pHdr=p[IP].ihl*4\n",
    "            ip_time=float(p.time)\n",
    "            if isUplink(p) and pLen-pHdr > GET_THRESH:\n",
    "                if ipDst in chunk:\n",
    "                    chunk[ipDst].slack_time = ip_time - chunk[ipDst].download_time\n",
    "                    avFlag=detectAV(chunk[ipDst])\n",
    "                    if avFlag==0:\n",
    "                        # chunk[ipDst].type='a'\n",
    "                        chunks.append(chunk[ipDst])\n",
    "                    elif avFlag==1:\n",
    "                        # chunk[ipDst].type='v'\n",
    "                        chunks.append(chunk[ipDst])\n",
    "                    else:\n",
    "                        chunk.pop(ipDst)\n",
    "                        downFlag.pop(ipDst)\n",
    "                chunk[ipDst] = Chunk(start_time=ip_time, get_size=pLen-pHdr, server_ip=ipDst)\n",
    "                downFlag[ipDst] = False\n",
    "            elif not isUplink(p) and pLen > DOWN_THRESH:\n",
    "                if ipSrc in chunk:\n",
    "                    if not downFlag[ipSrc]:\n",
    "                        chunk[ipSrc].ttfb = ip_time\n",
    "                        downFlag[ipSrc] = True\n",
    "                    chunk[ipSrc].download_time = ip_time\n",
    "                    chunk[ipSrc].chunk_size += pLen - pHdr\n",
    "                    chunk[ipSrc].protocol = p.proto\n",
    "    \n",
    "    for c in chunk.values():\n",
    "        avFlag=detectAV(c)\n",
    "        if avFlag==0:\n",
    "            # c.type='a'\n",
    "            chunks.append(c)\n",
    "        elif avFlag==1:\n",
    "            # c.type='v'\n",
    "            chunks.append(c)\n",
    "    return meta_time, chunks\n",
    "\n",
    "filename = 'RequetDataSetNew/A0/PCAP_FILES/baseline_Jan17_exp_31.pcap'\n",
    "meta_time, chunks=chunkDetection(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1516209610.386307 1516209610.410726 1516209612.950441 0.02435302734375 1247 624049  6, 1516209611.082223 1516209611.087837 1516209614.529326 0.03212308883666992 310 2129190  6, 1516209614.635162 1516209614.638517 1516209615.156041 0.029316186904907227 316 1587091  6, 1516209615.259879 1516209615.281233 1516209616.121418 0.03412294387817383 306 2209745  6, 1516209616.214358 1516209616.225509 1516209616.951287 0.07074189186096191 310 2209681  6, 1516209617.060617 1516209617.064965 1516209617.69758 0.04791998863220215 313 1627930  6, 1516209612.974794 1516209613.085303 1516209618.181602 0.5422348976135254 1365 132789  6, 1516209617.796378 1516209617.799761 1516209619.590904 0.029239892959594727 309 1536081  6, 1516209618.723837 1516209618.758569 1516209621.077217 0.0068759918212890625 1246 450948  6, 1516209621.084093 1516209621.103908 1516209621.48225 0.06220293045043945 1255 123272  6, 1516209619.657107 1516209619.661844 1516209621.994784 0.03506898880004883 316 1573298  6, 1516209622.075643 1516209622.099756 1516209623.522548 0.07048797607421875 320 2378154  6, 1516209623.593036 1516209623.596925 1516209623.709405 0.0031969547271728516 325 187333  6, 1516209623.15095 1516209623.314019 1516209624.496494 0.0004918575286865234 1370 509068  6, 1516209624.496986 1516209624.498317 1516209624.58387 0.003236055374145508 1257 121870  6, 1516209624.643005 1516209624.654625 1516209627.244286 0.0007710456848144531 1370 1439710  6, 1516209627.305875 1516209627.306382 1516209627.573585 8.996131896972656 1258 190758  6, 1516209636.569717 1516209636.590408 1516209637.733936 0.0009419918060302734 1259 629174  6, 1516209637.734878 1516209637.749293 1516209639.718409 3.7683908939361572 1371 1969338  6, 1516209643.4868 1516209643.503127 1516209645.42179 5.3186352252960205 1371 2089884  6, 1516209650.740425 1516209650.753322 1516209651.350077 10.63579511642456 1260 610504  6, 1516209661.985872 1516209662.006986 1516209664.131226 6.858290910720825 1371 2131536  6, 1516209670.989517 1516209671.007108 1516209671.679161 5.223062992095947 1260 489091  6, 1516209676.902224 1516209676.917696 1516209678.774774 6.966248035430908 1372 2063740  6, 1516209685.741022 1516209685.759737 1516209686.491457 14.255374908447266 1260 630944  6, 1516209700.746832 1516209700.765442 1516209702.770688 27.714512825012207 1373 1958394  6, 1516209730.485201 1516209730.501119 1516209731.951507 0.030055999755859375 1373 1628048  6, 1516209731.981563 1516209732.063441 1516209732.641678 18.342435836791992 1260 533457  6, 1516209750.984114 1516209751.001228 1516209752.784965 4.450613975524902 1373 1894860  6, 1516209757.235579 1516209757.251761 1516209758.063276 18.669888019561768 1260 613363  6, 1516209776.733164 1516209776.744854 1516209778.767332 12.721627950668335 1373 1801932  6, 1516209791.48896 1516209791.502894 1516209793.003453 8.482469081878662 1373 2085797  6, 1516209801.485922 1516209801.510287 1516209805.174566 2.5661349296569824 1373 1995683  6, 1516209807.740701 1516209807.771487 1516209808.336103 18.90724205970764 1260 589260  6, 1516209827.243345 1516209827.258889 1516209829.246286 23.743355989456177 1373 1918923  6, 1516209852.989642 1516209853.054675 1516209854.766983 0.010042905807495117 1373 1942776  6, 1516209854.791172 1516209854.802195 1516209855.83903 27.64270305633545 1260 616946  6, 1516209883.481733 1516209883.498127 1516209884.55934 3.6797409057617188 1373 1850316  6, 1516209888.285275 1516209888.3072 1516209888.819111 24.923014879226685 1260 592787  6, 1516209913.742126 1516209913.756084 1516209915.120197 3.6161580085754395 1373 1929042  6, 1516209918.736355 1516209918.750885 1516209919.338559 29.393433094024658 1260 605845  6, 1516209948.731992 1516209948.747609 1516209949.810645 18.964725971221924 1373 1503595  6, 1516209968.775371 1516209968.790211 1516209970.257944 0.03746294975280762 1373 1896162  6, 1516209970.295407 1516209970.398037 1516209970.85321 7.91800594329834 1260 525087  6, 1516209978.771216 1516209978.802384 1516209980.848299 17.929461002349854 1373 2104722  6, 1516209998.77776 1516209998.791467 1516210000.083852 0.00150299072265625 1373 1948444  6, 1516210000.088638 1516210000.337709 1516210000.818997 24.415229082107544 549 621030  6, 1516210025.280031 1516210025.350866 1516210027.442448 6.790917158126831 1373 1877436  6, 1516210034.233365 1516210034.265613 1516210036.036866 4.448321104049683 1373 1872263  6, 1516210040.485187 1516210040.504569 1516210040.915695 4.317913055419922 1260 484968  6, 1516210045.279363 1516210045.286865 1516210047.063644 7.917160987854004 1373 1975015  6, 1516210054.980805 1516210055.011688 1516210057.287586 8.695404052734375 1373 2018014  6, 1516210065.98299 1516210066.003712 1516210067.890474 3.841585874557495 1373 2149308  6, 1516210071.73206 1516210071.748331 1516210071.930315 2.051754951477051 1260 198924  6, 1516209624.306796 1516209624.312524 1516209625.674749 0 319 892970  6, 1516210073.98207 1516210073.997257 1516210075.529079 0 1373 1981955  6]\n"
     ]
    }
   ],
   "source": [
    "print(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Time:25.146851778030396\n",
      "lenth:84540\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "filename = 'RequetDataSetNew/A0/PCAP_FILES/baseline_Jan17_exp_31.pcap'\n",
    "pacpfile = rdpcap(filename)\n",
    "end = time.time()\n",
    "print(f\"Use Time:{end - start}\")\n",
    "print(f'lenth:{len(pacpfile)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipSrc:192.168.1.190, ipDst:172.217.12.142, pLen:379, pHdr:20, ip_time:1516209607.012159, end_time:1516209607.012159\n",
      "ipSrc:192.168.1.190, ipDst:172.217.12.142, pLen:510, pHdr:20, ip_time:1516209607.05867, end_time:1516209607.05867\n",
      "{'172.217.12.142': 1516209607.05867 0 0 0 490 0  }\n"
     ]
    }
   ],
   "source": [
    "GET_THRESH = 300  # bytes\n",
    "DOWN_THRESH = 300  # bytes\n",
    "VIDEO_CHUNK_GETSIZE = 700  # bytes\n",
    "AUDIO_CHUNK_GETSIZE = 600  # bytes\n",
    "import scapy.layers as layers\n",
    "\n",
    "def isUplink(p):\n",
    "    return p[IP].src.startswith('192.168.')\n",
    "def detectAV(c):\n",
    "    if abs(c.get_size-VIDEO_CHUNK_GETSIZE) > abs(c.get_size-AUDIO_CHUNK_GETSIZE):\n",
    "        flag=0\n",
    "    else:\n",
    "        flag=1\n",
    "    if c.chunk_size<=80*1024:\n",
    "        flag=2\n",
    "    return flag\n",
    "chunk = {}\n",
    "chunks = []\n",
    "downFlag = {}\n",
    "#  用show显示包的内容\n",
    "count=0\n",
    "# print(pacpfile[0].show())\n",
    "IP = layers.inet.IP\n",
    "for p in pacpfile[0:13]:\n",
    "    if p.haslayer(IP):\n",
    "        ipSrc = p[IP].src\n",
    "        ipDst = p[IP].dst\n",
    "        pLen = p[IP].len\n",
    "        pHdr = p[IP].ihl*4\n",
    "        ip_time = float(p.time)\n",
    "        end_time = ip_time\n",
    "        # print(p.show())\n",
    "        if isUplink(p) and pLen-pHdr > GET_THRESH:\n",
    "            print(f'ipSrc:{ipSrc}, ipDst:{ipDst}, pLen:{pLen}, pHdr:{pHdr}, ip_time:{ip_time}, end_time:{end_time}')\n",
    "            if ipDst in chunk:\n",
    "                chunk[ipDst].slack_time = ip_time - chunk[ipDst].download_time\n",
    "                avFlag = detectAV(chunk[ipDst])\n",
    "                if avFlag == 0:\n",
    "                    # chunk[ipDst].type='a'\n",
    "                    chunks.append(chunk[ipDst])\n",
    "                elif avFlag == 1:\n",
    "                    # chunk[ipDst].type='v'\n",
    "                    chunks.append(chunk[ipDst])\n",
    "                else:\n",
    "                    chunk.pop(ipDst)\n",
    "                    downFlag.pop(ipDst)\n",
    "            chunk[ipDst] = Chunk(start_time=ip_time, get_size=pLen-pHdr, server_ip=ipDst)\n",
    "            downFlag[ipDst] = False\n",
    "        elif not isUplink(p) and pLen > DOWN_THRESH:\n",
    "            if ipSrc in chunk:\n",
    "                if not downFlag[ipSrc]:\n",
    "                    chunk[ipSrc].ttfb = ip_time\n",
    "                    downFlag[ipSrc] = True\n",
    "                chunk[ipSrc].download_time = ip_time\n",
    "                chunk[ipSrc].chunk_size += pLen - pHdr\n",
    "                chunk[ipSrc].protocol = p.proto\n",
    "for c in chunk.values():\n",
    "    avFlag=detectAV(c)\n",
    "    if avFlag==0:\n",
    "        # c.type='a'\n",
    "        chunks.append(c)\n",
    "    elif avFlag==1:\n",
    "        # c.type='v'\n",
    "        chunks.append(c)\n",
    "# f\"{self.start_time} {self.ttfb} {self.download_time} {self.slack_time} {self.get_size} {self.chunk_size} {self.type} {self.protocol}\"\n",
    "print(chunk)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'172.217.10.102': 1516209607.812766 0 0 0 448 0  , '23.206.171.9': 1516209624.306796 1516209624.312524 1516209625.674749 0 319 892970  6, '172.217.10.226': 1516209626.317585 1516209626.340094 1516209626.340094 0 536 879  6, '172.217.15.100': 1516209626.419784 0 0 0 348 0  , '172.217.6.194': 1516209636.556193 0 0 0 485 0  , '172.217.10.67': 1516209671.121419 0 0 0 1400 0  , '172.217.11.10': 1516209717.980839 1516209718.011638 1516209718.012025 0 858 2694  6, '172.217.11.3': 1516209966.46761 1516209966.510818 1516209966.511161 0 392 1391  6, '173.194.7.39': 1516210073.98207 1516210073.997257 1516210075.529079 0 1373 1981955  6, '172.217.6.206': 1516210169.404179 1516210169.408949 1516210169.456366 0 397 49286  6, '172.217.12.142': 1516210196.055187 0 0 0 590 0  , '172.217.11.19': 1516210198.297022 0 0 0 367 0  }\n"
     ]
    }
   ],
   "source": [
    "print(chunk)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['start_time', 'server_ip', 'type', 'ttfb', 'download_time', 'get_size', 'chunk_size', 'rel_start_time', 'rel_end_time']\n",
    "df_chunk=pd.DataFrame(columns=columns)\n",
    "\n",
    "\n",
    "for c in chunks:\n",
    "    start_time = c.start_time\n",
    "    server_ip = c.server_ip\n",
    "    type = c.type\n",
    "    ttfb = c.ttfb - c.start_time\n",
    "    download_time = c.download_time - c.start_time\n",
    "    get_size = c.get_size\n",
    "    chunk_size = c.chunk_size\n",
    "    rel_start_time = start_time-meta_time\n",
    "    rel_end_time = c.download_time - meta_time\n",
    "    s = pd.Series([start_time, server_ip, type, ttfb, download_time, get_size, chunk_size, rel_start_time, rel_end_time], index=columns)\n",
    "    df_chunk.loc[len(df_chunk)] = s\n",
    "\n",
    "av_getsize_gap = df_chunk.get_size.mean()\n",
    "\n",
    "for i in range(len(df_chunk)):\n",
    "    df_chunk.loc[i, 'type'] = 'a' if df_chunk.loc[i, 'get_size'] < av_getsize_gap else 'v'\n",
    "\n",
    "df_chunk.sort_values(by='start_time', inplace=True)\n",
    "df_chunk.to_csv('results/chunk_detection/A0/baseline_Jan17_exp_30.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_chunk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [22], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m df_chunk\n",
      "\u001B[1;31mNameError\u001B[0m: name 'df_chunk' is not defined"
     ]
    }
   ],
   "source": [
    "df_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = df_chunk['start_time'].min()\n",
    "end_time = df_chunk['start_time'].max()\n",
    "\n",
    "columns=['timestamp']+[str(i) for i in range(1,121)]\n",
    "\n",
    "df_120features=pd.DataFrame(columns=columns)\n",
    "\n",
    "for t_msec in range(int(start_time*1000), int(end_time*1000+100), 100):\n",
    "    s = [t_msec]\n",
    "    t = t_msec/1000\n",
    "    for w in range(1, 21):\n",
    "        period = w*10.0\n",
    "        if t-period<start_time:\n",
    "            total_number_of_chunks_v = -1\n",
    "            avg_chunk_size_v = -1\n",
    "            download_time_v = -1\n",
    "            total_number_of_chunks_a = -1\n",
    "            avg_chunk_size_a = -1\n",
    "            download_time_a = -1\n",
    "        else:\n",
    "            total_number_of_chunks_v = df_chunk[(df_chunk['type']=='v') & (df_chunk['start_time']>t-period) & (df_chunk['start_time']<t)].shape[0]\n",
    "            avg_chunk_size_v = df_chunk[(df_chunk['type']=='v') & (df_chunk['start_time']>t-period) & (df_chunk['start_time']<t)]['chunk_size'].mean()\n",
    "            download_time_v = df_chunk[(df_chunk['type']=='v') & (df_chunk['start_time']>t-period) & (df_chunk['start_time']<t)]['download_time'].sum()\n",
    "            total_number_of_chunks_a = df_chunk[(df_chunk['type']=='a') & (df_chunk['start_time']>t-period) & (df_chunk['start_time']<t)].shape[0]\n",
    "            avg_chunk_size_a = df_chunk[(df_chunk['type']=='a') & (df_chunk['start_time']>t-period) & (df_chunk['start_time']<t)]['chunk_size'].mean()\n",
    "            download_time_a = df_chunk[(df_chunk['type']=='a') & (df_chunk['start_time']>t-period) & (df_chunk['start_time']<t)]['download_time'].sum()\n",
    "        s += [total_number_of_chunks_v, avg_chunk_size_v, download_time_v, total_number_of_chunks_a, avg_chunk_size_a, download_time_a]\n",
    "    \n",
    "    df_120features.loc[len(df_120features)] = s\n",
    "\n",
    "df_120features.to_csv('results/120features/A0/baseline_Jan17_exp_30.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32mD:\\Program\\Anaconda\\envs\\dip2022\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3803\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3802\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3803\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3804\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32mD:\\Program\\Anaconda\\envs\\dip2022\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mD:\\Program\\Anaconda\\envs\\dip2022\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2263\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2273\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [12], line 15\u001B[0m\n\u001B[0;32m     12\u001B[0m video_chunk_prev \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mchunk_size\u001B[39m\u001B[38;5;124m'\u001B[39m:[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdownload_time\u001B[39m\u001B[38;5;124m'\u001B[39m:[\u001B[38;5;241m0\u001B[39m]}\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(df_audio_chunk)):\n\u001B[1;32m---> 15\u001B[0m     audio_chunk_prev[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mchunk_size\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mappend(audio_chunk_prev[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mchunk_size\u001B[39m\u001B[38;5;124m'\u001B[39m][i] \u001B[38;5;241m+\u001B[39m df_audio_chunk\u001B[38;5;241m.\u001B[39mloc[i, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mchunk_size\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m     16\u001B[0m     audio_chunk_prev[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdownload_time\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mappend(audio_chunk_prev[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdownload_time\u001B[39m\u001B[38;5;124m'\u001B[39m][i] \u001B[38;5;241m+\u001B[39m df_audio_chunk\u001B[38;5;241m.\u001B[39mloc[i, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdownload_time\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(df_video_chunk)):\n",
      "File \u001B[1;32mD:\\Program\\Anaconda\\envs\\dip2022\\lib\\site-packages\\pandas\\core\\indexing.py:1066\u001B[0m, in \u001B[0;36m_LocationIndexer.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   1064\u001B[0m     key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(com\u001B[38;5;241m.\u001B[39mapply_if_callable(x, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m key)\n\u001B[0;32m   1065\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_is_scalar_access(key):\n\u001B[1;32m-> 1066\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_value\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtakeable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_takeable\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1067\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_tuple(key)\n\u001B[0;32m   1068\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1069\u001B[0m     \u001B[38;5;66;03m# we by definition only have the 0th axis\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Program\\Anaconda\\envs\\dip2022\\lib\\site-packages\\pandas\\core\\frame.py:3921\u001B[0m, in \u001B[0;36mDataFrame._get_value\u001B[1;34m(self, index, col, takeable)\u001B[0m\n\u001B[0;32m   3915\u001B[0m engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex\u001B[38;5;241m.\u001B[39m_engine\n\u001B[0;32m   3917\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex, MultiIndex):\n\u001B[0;32m   3918\u001B[0m     \u001B[38;5;66;03m# CategoricalIndex: Trying to use the engine fastpath may give incorrect\u001B[39;00m\n\u001B[0;32m   3919\u001B[0m     \u001B[38;5;66;03m#  results if our categories are integers that dont match our codes\u001B[39;00m\n\u001B[0;32m   3920\u001B[0m     \u001B[38;5;66;03m# IntervalIndex: IntervalTree has no get_loc\u001B[39;00m\n\u001B[1;32m-> 3921\u001B[0m     row \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3922\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m series\u001B[38;5;241m.\u001B[39m_values[row]\n\u001B[0;32m   3924\u001B[0m \u001B[38;5;66;03m# For MultiIndex going through engine effectively restricts us to\u001B[39;00m\n\u001B[0;32m   3925\u001B[0m \u001B[38;5;66;03m#  same-length tuples; see test_get_set_value_no_partial_indexing\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Program\\Anaconda\\envs\\dip2022\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3803\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[0;32m   3804\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m-> 3805\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3806\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3807\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3808\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3809\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m   3810\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: 0"
     ]
    }
   ],
   "source": [
    "start_time = df_chunk['start_time'].min()\n",
    "end_time = df_chunk['start_time'].max()\n",
    "\n",
    "columns=['timestamp']+[str(i) for i in range(1,121)]\n",
    "\n",
    "df_120features=pd.DataFrame(columns=columns)\n",
    "\n",
    "df_audio_chunk=df_chunk[df_chunk.type=='a']\n",
    "df_video_chunk=df_chunk[df_chunk.type=='v']\n",
    "\n",
    "audio_chunk_prev = {'chunk_size':[0], 'download_time':[0]}\n",
    "video_chunk_prev = {'chunk_size':[0], 'download_time':[0]}\n",
    "\n",
    "for i in range(len(df_audio_chunk)):\n",
    "    audio_chunk_prev['chunk_size'].append(audio_chunk_prev['chunk_size'][i] + df_audio_chunk.loc[i, 'chunk_size'])\n",
    "    audio_chunk_prev['download_time'].append(audio_chunk_prev['download_time'][i] + df_audio_chunk.loc[i, 'download_time'])\n",
    "\n",
    "for i in range(len(df_video_chunk)):\n",
    "    video_chunk_prev['chunk_size'].append(video_chunk_prev['chunk_size'][i] + df_video_chunk.loc[i, 'chunk_size'])\n",
    "    video_chunk_prev['download_time'].append(video_chunk_prev['download_time'][i] + df_video_chunk.loc[i, 'download_time'])\n",
    "\n",
    "\n",
    "for t_msec in range(int(start_time*1000), int(end_time*1000+100), 100):\n",
    "    s = [t_msec]\n",
    "    t = t_msec/1000\n",
    "    for w in range(1, 21):\n",
    "        l_audio = 0\n",
    "        r_audio = 0\n",
    "        l_video = 0\n",
    "        r_video = 0\n",
    "        period = w * 10.0\n",
    "        l_t = t - period\n",
    "        if l_t<start_time:\n",
    "            total_number_of_chunks_v = -1\n",
    "            avg_chunk_size_v = -1\n",
    "            download_time_v = -1\n",
    "            total_number_of_chunks_a = -1\n",
    "            avg_chunk_size_a = -1\n",
    "            download_time_a = -1\n",
    "        else:\n",
    "            while df_audio_chunk.loc[l_audio, 'start_time'] < l_t:\n",
    "                l_audio += 1\n",
    "            while df_audio_chunk.loc[r_audio, 'start_time'] <= t:\n",
    "                r_audio += 1\n",
    "            while df_video_chunk.loc[l_video, 'start_time'] < l_t:\n",
    "                l_video += 1\n",
    "            while df_video_chunk.loc[r_video, 'start_time'] <= t:\n",
    "                r_video += 1\n",
    "            total_number_of_chunks_v = r_video - l_video \n",
    "            avg_chunk_size_v = video_chunk_prev['chunk_size'][r_video] - video_chunk_prev['chunk_size'][l_video]\n",
    "            download_time_v = video_chunk_prev['download_time'][r_video] - video_chunk_prev['download_time'][l_video]\n",
    "            total_number_of_chunks_a = r_audio - l_audio\n",
    "            avg_chunk_size_a = audio_chunk_prev['chunk_size'][r_audio] - audio_chunk_prev['chunk_size'][l_audio]\n",
    "            download_time_a = audio_chunk_prev['download_time'][r_audio-1] - audio_chunk_prev['download_time'][l_audio-1]\n",
    "        s += [total_number_of_chunks_v, avg_chunk_size_v, download_time_v, total_number_of_chunks_a, avg_chunk_size_a, download_time_a]\n",
    "    \n",
    "    df_120features.loc[len(df_120features)] = s\n",
    "\n",
    "df_120features.to_csv('results/120features/A0/baseline_Jan17_exp_30.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "dip2022",
   "language": "python",
   "display_name": "dip2022"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
